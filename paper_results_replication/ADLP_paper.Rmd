---
title: "R Notebook"
output: html_notebook
---

# Introduction:

This Rmarkdown file seeks to reproduce the key results in the paper "Ensemble distributional forecasting for insurance loss reserving", which contains the following sections:

- **Package loading**: Load the required packages used in the paper and relevant functions from the `ADLP` package
- **Claims Simulation**: Simulate the claims triangles used in the paper based on the `SynthETIC` package; the default setting is to simulate 100 triangles with size 40x40. 
- **Create component functions**: Create and fit all the component models to be used in the ADLP ensemble based on the list of models shown in the paper
- **Fit ADLP**: Calibrate all the ADLP ensembles used in the paper
- **Model evaluation with proper scoring rules**: Evaluate the fitted ADLP ensembles based on the Log Score used in the paper
- **Reserve calculation**: Calculate the aggregate reserve estimation for the selected ADLP ensemble in the paper



# Package loading: 

```{r}
Time_start <- Sys.time()
```


```{r}

# Load the packages:
devtools::load_all("../ADLP-package")
#devtools::document()
library(gamlss)
library(gamlss.dist)
library(gamlss.inf)
library(tweedie)
library(ggplot2)
```

Define a custom ADLP function to fit the equally weighted ensemble and BMV:

```{r}
## Define a custom ADLP function to fit the Equally weighted ensemble and BMV:
adlp_custom <- function(
    components_lst, weights, partition_func,...
) {
    model_weights <- weights

    z <- list(
        components_lst = components_lst,
        partition_func = partition_func,
        model_weights = model_weights
    )
    class(z) <- "adlp_custom"

    return (z)
}
```

Define a a function to partition the data into training set, validation set, and test set: 

```{r Define the data splitting function}

train_val_split <- function(df) {

    # Subsets claims dataframe into 6 training, validation and test sets
    # Construction of Training Set:
    train_1 <- df[df$calendar<=34, ]
    train_2 <- df[df$origin==1 & 34<=df$dev & df$dev<=40, ]
    train_3 <- df[35<=df$calendar & df$calendar<=36 & df$dev <=2, ]
    train_4 <- df[36<=df$origin & df$dev==1, ]
    train<-rbind(train_1,train_2,train_3,train_4)
    train[order(train$origin),]

    # Construction of Validation set:
    valid_1 <- df[35<=df$calendar & df$calendar<=41 & 2<=df$origin & 3<=df$dev, ]
    valid_2 <- df[35<=df$origin & df$origin<=39 & df$dev == 2, ]
    valid<-rbind(valid_1,valid_2)
    valid[order(valid$origin),]

    return(list(train=train, valid=valid))
}
```

# Claims Simulation

Simulate the claims data required for the fitting:

```{r Simulation}
simulate_claims <- F

## Define the number of simulations and th triangle size
n.sims <- 100
tri.size <-40

## Install the 'SynthETIC' and the 'ChainLadder' packages if required:
if (!require(SynthETIC)) install.packages('SynthETIC')
if (!require(ChainLadder)) install.packages('ChainLadder')
library("SynthETIC")
library("ChainLadder")

if (simulate_claims) {source('simulation/simulate_claims.R')}
```


# Create component functions

Define all the component functions to be used in the fitting:

```{r Define component functions}
source('components/define_component_func.R')
```

Fit all the component functions on the data:

- The output is `components_list`, which is a list storing all the fitted `adlp_components` objects for each simulated data set.

```{r Fit all component functions}
source('components/fit_all_components.R')
```


# Fit ADLP

## Defining custom partition functions that are used in the paper

```{r}
split_points_40 <- c(3, 4, 5, 7, 9, 11, 13, 14, 15, 16, 17, 18, 19, 23, 26, 28, 31, 33)


        par1_2_40 <- function(df) {
            return (list(
                subset1 = df[(as.numeric(as.character(df$origin)) >= 1) & (as.numeric(as.character(df$origin)) <= split_points_40[1]), ],
                subset2 = df[(as.numeric(as.character(df$origin)) >= split_points_40[1] + 1) & (as.numeric(as.character(df$origin)) <= 40), ]
            ))
        }
        
        par2_2_40 <- function(df) {
            return (list(
                subset1 = df[(as.numeric(as.character(df$origin)) >= 1) & (as.numeric(as.character(df$origin)) <= split_points_40[2]), ],
                subset2 = df[(as.numeric(as.character(df$origin)) >= split_points_40[2] + 1) & (as.numeric(as.character(df$origin)) <= 40), ]
            ))
        }
        
        par3_2_40 <- function(df) {
            return (list(
                subset1 = df[(as.numeric(as.character(df$origin)) >= 1) & (as.numeric(as.character(df$origin)) <= split_points_40[3]), ],
                subset2 = df[(as.numeric(as.character(df$origin)) >= split_points_40[3] + 1) & (as.numeric(as.character(df$origin)) <= 40), ]
            ))
        }
         par4_2_40 <- function(df) {
            return (list(
                subset1 = df[(as.numeric(as.character(df$origin)) >= 1) & (as.numeric(as.character(df$origin)) <= split_points_40[4]), ],
                subset2 = df[(as.numeric(as.character(df$origin)) >= split_points_40[4] + 1) & (as.numeric(as.character(df$origin)) <= 40), ]
            ))
         }
         
          par5_2_40 <- function(df) {
            return (list(
                subset1 = df[(as.numeric(as.character(df$origin)) >= 1) & (as.numeric(as.character(df$origin)) <= split_points_40[5]), ],
                subset2 = df[(as.numeric(as.character(df$origin)) >= split_points_40[5] + 1) & (as.numeric(as.character(df$origin)) <= 40), ]
            ))
          }
          
           par6_2_40 <- function(df) {
            return (list(
                subset1 = df[(as.numeric(as.character(df$origin)) >= 1) & (as.numeric(as.character(df$origin)) <= split_points_40[6]), ],
                subset2 = df[(as.numeric(as.character(df$origin)) >= split_points_40[6] + 1) & (as.numeric(as.character(df$origin)) <= 40), ]
            ))
           }
           
            par7_2_40 <- function(df) {
            return (list(
                subset1 = df[(as.numeric(as.character(df$origin)) >= 1) & (as.numeric(as.character(df$origin)) <= split_points_40[7]), ],
                subset2 = df[(as.numeric(as.character(df$origin)) >= split_points_40[7] + 1) & (as.numeric(as.character(df$origin)) <= 40), ]
            ))
            }
             par8_2_40 <- function(df) {
            return (list(
                subset1 = df[(as.numeric(as.character(df$origin)) >= 1) & (as.numeric(as.character(df$origin)) <= split_points_40[8]), ],
                subset2 = df[(as.numeric(as.character(df$origin)) >= split_points_40[8] + 1) & (as.numeric(as.character(df$origin)) <= 40), ]
            ))
             }
             
              par9_2_40 <- function(df) {
            return (list(
                subset1 = df[(as.numeric(as.character(df$origin)) >= 1) & (as.numeric(as.character(df$origin)) <= split_points_40[9]), ],
                subset2 = df[(as.numeric(as.character(df$origin)) >= split_points_40[9] + 1) & (as.numeric(as.character(df$origin)) <= 40), ]
            ))
              }
               par10_2_40 <- function(df) {
            return (list(
                subset1 = df[(as.numeric(as.character(df$origin)) >= 1) & (as.numeric(as.character(df$origin)) <= split_points_40[10]), ],
                subset2 = df[(as.numeric(as.character(df$origin)) >= split_points_40[10] + 1) & (as.numeric(as.character(df$origin)) <= 40), ]
            ))
               }
               
                par11_2_40 <- function(df) {
            return (list(
                subset1 = df[(as.numeric(as.character(df$origin)) >= 1) & (as.numeric(as.character(df$origin)) <= split_points_40[11]), ],
                subset2 = df[(as.numeric(as.character(df$origin)) >= split_points_40[11] + 1) & (as.numeric(as.character(df$origin)) <= 40), ]
            ))
                }
                 par12_2_40 <- function(df) {
            return (list(
                subset1 = df[(as.numeric(as.character(df$origin)) >= 1) & (as.numeric(as.character(df$origin)) <= split_points_40[12]), ],
                subset2 = df[(as.numeric(as.character(df$origin)) >= split_points_40[12] + 1) & (as.numeric(as.character(df$origin)) <= 40), ]
            ))
                 }
                 
                  par13_2_40 <- function(df) {
            return (list(
                subset1 = df[(as.numeric(as.character(df$origin)) >= 1) & (as.numeric(as.character(df$origin)) <= split_points_40[13]), ],
                subset2 = df[(as.numeric(as.character(df$origin)) >= split_points_40[13] + 1) & (as.numeric(as.character(df$origin)) <= 40), ]
            ))
                  }
                  
                   par14_2_40 <- function(df) {
            return (list(
                subset1 = df[(as.numeric(as.character(df$origin)) >= 1) & (as.numeric(as.character(df$origin)) <= split_points_40[14]), ],
                subset2 = df[(as.numeric(as.character(df$origin)) >= split_points_40[14] + 1) & (as.numeric(as.character(df$origin)) <= 40), ]
            ))
        }
        
                    par15_2_40 <- function(df) {
            return (list(
                subset1 = df[(as.numeric(as.character(df$origin)) >= 1) & (as.numeric(as.character(df$origin)) <= split_points_40[15]), ],
                subset2 = df[(as.numeric(as.character(df$origin)) >= split_points_40[15] + 1) & (as.numeric(as.character(df$origin)) <= 40), ]
            ))
                    }
                     par16_2_40 <- function(df) {
            return (list(
                subset1 = df[(as.numeric(as.character(df$origin)) >= 1) & (as.numeric(as.character(df$origin)) <= split_points_40[16]), ],
                subset2 = df[(as.numeric(as.character(df$origin)) >= split_points_40[16] + 1) & (as.numeric(as.character(df$origin)) <= 40), ]
            ))
                     }
                    par17_2_40 <- function(df) {
                                return (list(
                                    subset1 = df[(as.numeric(as.character(df$origin)) >= 1) & (as.numeric(as.character(df$origin)) <= split_points_40[17]), ],
                                    subset2 = df[(as.numeric(as.character(df$origin)) >= split_points_40[17] + 1) & (as.numeric(as.character(df$origin)) <= 40), ]
                                ))
                      }
                par18_2_40 <- function(df) {
                            return (list(
                                subset1 = df[(as.numeric(as.character(df$origin)) >= 1) & (as.numeric(as.character(df$origin)) <= split_points_40[18]), ],
                                subset2 = df[(as.numeric(as.character(df$origin)) >= split_points_40[18] + 1) & (as.numeric(as.character(df$origin)) <= 40), ]
                            ))
                                }
                
```


## Fit all ADLP ensembles used in the paper:

```{r}
## Define a list to store the fitted SLP ensembles: 

fit_0_40 <- list()

## Perform the simulations:
suppressWarnings({
for (sim in 1:n.sims) {
    set.seed(20200130+sim)
    # Train on train, test on valid-test
    past_data <- read.csv(sprintf('simulation/triangle_%s-data/sim%s-past-data.csv', tri.size, sim))
    full_data <- read.csv(sprintf('simulation/triangle_%s-data/sim%s-full-data.csv', tri.size, sim))
    past_data$tau_Ga<-tau_Ga
    past_data$tau_LN<-tau_LN
    full_data$tau_Ga<-tau_Ga
    full_data$tau_LN<-tau_LN
    
    #### Partition the data into training and validation set #####
    insample_data <- past_data
    train_val <- train_val_split(insample_data)

    components <- components_list[[sim]]

        fit_0_40[[sim]] <- adlp(
            components_lst = components,
            newdata = train_val$valid,
            partition_func = adlp_partition_none,
            param_tol = 0
        )
}

})

```




```{r}
## Define a list to store the fitted ADLP ensembles: 

fit_1_40 <- list()
fit_2_40 <- list()
fit_3_40 <- list()
fit_4_40 <- list()
fit_5_40 <- list()
fit_6_40 <- list()
fit_7_40 <- list()
fit_8_40 <- list()
fit_9_40 <- list()
fit_10_40 <- list()
fit_11_40 <- list()
fit_12_40 <- list()
fit_13_40 <- list()
fit_14_40 <- list()
fit_15_40 <- list()
fit_16_40 <- list()
fit_17_40 <- list()
fit_18_40 <- list()

## Perform the simulations:
suppressWarnings({
for (sim in 1:n.sims) {
    set.seed(20200130+sim)
     # Train on train, test on valid-test
    past_data <- read.csv(sprintf('simulation/triangle_%s-data/sim%s-past-data.csv', tri.size, sim))
    full_data <- read.csv(sprintf('simulation/triangle_%s-data/sim%s-full-data.csv', tri.size, sim))
    past_data$tau_Ga<-tau_Ga
    past_data$tau_LN<-tau_LN
    full_data$tau_Ga<-tau_Ga
    full_data$tau_LN<-tau_LN
    
    #### Partition the data into training and validation set #####
    insample_data <- past_data
    train_val <- train_val_split(insample_data)
    

    components <- components_list[[sim]]

        fit_1_40[[sim]] <- adlp(
            components_lst = components,
            newdata = train_val$valid,
            partition_func = par1_2_40,
            param_tol = 0
        )
        
        fit_2_40[[sim]] <- adlp(
            components_lst = components,
            newdata = train_val$valid,
            partition_func = par2_2_40,
            param_tol = 0
        )
        
        fit_3_40[[sim]] <- adlp(
            components_lst = components,
            newdata = train_val$valid,
            partition_func = par3_2_40,
            param_tol = 0
        )
        
        fit_4_40[[sim]] <- adlp(
            components_lst = components,
            newdata = train_val$valid,
            partition_func = par4_2_40,
            param_tol = 0
        )
        
        fit_5_40[[sim]] <- adlp(
            components_lst = components,
            newdata = train_val$valid,
            partition_func = par5_2_40,
            param_tol = 0
        )
        
        fit_6_40[[sim]] <- adlp(
            components_lst = components,
            newdata = train_val$valid,
            partition_func = par6_2_40,
            param_tol = 0
        )
        
        fit_7_40[[sim]] <- adlp(
            components_lst = components,
            newdata = train_val$valid,
            partition_func = par7_2_40,
            param_tol = 0
        )
        
        fit_8_40[[sim]] <- adlp(
            components_lst = components,
            newdata = train_val$valid,
            partition_func = par8_2_40,
            param_tol = 0
        )
        
        fit_9_40[[sim]] <- adlp(
            components_lst = components,
            newdata = train_val$valid,
            partition_func = par9_2_40,
            param_tol = 0
        )
        
        fit_10_40[[sim]] <- adlp(
            components_lst = components,
            newdata = train_val$valid,
            partition_func = par10_2_40,
            param_tol = 0
        )
        
        fit_11_40[[sim]] <- adlp(
            components_lst = components,
            newdata = train_val$valid,
            partition_func = par11_2_40,
            param_tol = 0
        )
        
        fit_12_40[[sim]] <- adlp(
            components_lst = components,
            newdata = train_val$valid,
            partition_func = par12_2_40,
            param_tol = 0
        )
        
        fit_13_40[[sim]] <- adlp(
            components_lst = components,
            newdata = train_val$valid,
            partition_func = par13_2_40,
            param_tol = 0
        )
        
        fit_14_40[[sim]] <- adlp(
            components_lst = components,
            newdata = train_val$valid,
            partition_func = par14_2_40,
            param_tol = 0
        )
        
        fit_15_40[[sim]] <- adlp(
            components_lst = components,
            newdata = train_val$valid,
            partition_func = par15_2_40,
            param_tol = 0
        )
        
        fit_16_40[[sim]] <- adlp(
            components_lst = components,
            newdata = train_val$valid,
            partition_func = par16_2_40,
            param_tol = 0
        )
        
        fit_17_40[[sim]] <- adlp(
            components_lst = components,
            newdata = train_val$valid,
            partition_func = par17_2_40,
            param_tol = 0
        )
        
        fit_18_40[[sim]] <- adlp(
            components_lst = components,
            newdata = train_val$valid,
            partition_func = par18_2_40,
            param_tol = 0
        )

}

  })

```

Fit the equally weighted ensemble:

```{r}
## Define the customized weights (In this case, it is equally weighted): 
Equally_weights <- list(rep(1/18, 18))
fit_EW <- list()
for (sim in 1:n.sims){
components <- components_list[[sim]]
fit_EW[[sim]] <- adlp_custom(components_lst = components,
weights = Equally_weights,
partition_func = adlp_partition_none)}


```

Fit the BMV model:

```{r}
## Define a list to store the fitted SLP ensembles: 

fit_BMV <- list()

## Perform the simulations:
suppressWarnings({
for (sim in 1:n.sims) {
    # Train on train, test on valid-test
    past_data <- read.csv(sprintf('simulation/triangle_%s-data/sim%s-past-data.csv', tri.size, sim))
    full_data <- read.csv(sprintf('simulation/triangle_%s-data/sim%s-full-data.csv', tri.size, sim))
    past_data$tau_Ga<-tau_Ga
    past_data$tau_LN<-tau_LN
    full_data$tau_Ga<-tau_Ga
    full_data$tau_LN<-tau_LN
    
    #### Partition the data into training and validation set #####
    insample_data <- past_data
    train_val <- train_val_split(insample_data)

    components <- components_list[[sim]]
    
    # Calculate the density and log score of component models attained in the validation set:
    component_dens = calc_adlp_component_lst(
            components_lst = components, newdata = train_val$valid, model = "train", calc = "pdf"
        )
    component_dens <- subset(component_dens, select = -c(origin, dev))
    valid_logs <- apply(component_dens, MARGIN = 2, FUN = function(x) mean(log(x)))
    
    # Find the index for model with the highest log score attained in validation set (i.e., the BMV model)
    BMV_index <- as.numeric(which.max(valid_logs))
    
    # Assign a weight of 1 to BMV and 0 for others:
    w <- rep(0, 18)
    w[BMV_index] <- 1
    
    # Create an ADLP object using the BMV weights: 
    fit_BMV[[sim]] <- adlp_custom(components_lst = components,
                weights = list(w),
                partition_func = adlp_partition_none)
    
    
}

  })
```



# Model evaluation with proper scoring rules: 

## Log Score: 

Calculate the Log Scores for all the ensembles used in the paper: 

```{r}
#############################################################################
## Define a matrix to store the Log Score outputs of the ensemble ###########
#############################################################################

ensemble_logS_out_fit_1_40 <- matrix(NA, nrow = nrow(full_data[full_data$calendar > 41,]), ncol = n.sims)
ensemble_logS_out_fit_2_40 <- matrix(NA, nrow = nrow(full_data[full_data$calendar > 41,]), ncol = n.sims)
ensemble_logS_out_fit_3_40 <- matrix(NA, nrow = nrow(full_data[full_data$calendar > 41,]), ncol = n.sims)
ensemble_logS_out_fit_4_40 <- matrix(NA, nrow = nrow(full_data[full_data$calendar > 41,]), ncol = n.sims)
ensemble_logS_out_fit_5_40 <- matrix(NA, nrow = nrow(full_data[full_data$calendar > 41,]), ncol = n.sims)
ensemble_logS_out_fit_6_40 <- matrix(NA, nrow = nrow(full_data[full_data$calendar > 41,]), ncol = n.sims)
ensemble_logS_out_fit_7_40 <- matrix(NA, nrow = nrow(full_data[full_data$calendar > 41,]), ncol = n.sims)
ensemble_logS_out_fit_8_40 <- matrix(NA, nrow = nrow(full_data[full_data$calendar > 41,]), ncol = n.sims)
ensemble_logS_out_fit_9_40 <- matrix(NA, nrow = nrow(full_data[full_data$calendar > 41,]), ncol = n.sims)
ensemble_logS_out_fit_10_40 <- matrix(NA, nrow = nrow(full_data[full_data$calendar > 41,]), ncol = n.sims)
ensemble_logS_out_fit_11_40 <- matrix(NA, nrow = nrow(full_data[full_data$calendar > 41,]), ncol = n.sims)
ensemble_logS_out_fit_12_40 <- matrix(NA, nrow = nrow(full_data[full_data$calendar > 41,]), ncol = n.sims)
ensemble_logS_out_fit_13_40 <- matrix(NA, nrow = nrow(full_data[full_data$calendar > 41,]), ncol = n.sims)
ensemble_logS_out_fit_14_40 <- matrix(NA, nrow = nrow(full_data[full_data$calendar > 41,]), ncol = n.sims)
ensemble_logS_out_fit_15_40 <- matrix(NA, nrow = nrow(full_data[full_data$calendar > 41,]), ncol = n.sims)
ensemble_logS_out_fit_16_40 <- matrix(NA, nrow = nrow(full_data[full_data$calendar > 41,]), ncol = n.sims)
ensemble_logS_out_fit_17_40 <- matrix(NA, nrow = nrow(full_data[full_data$calendar > 41,]), ncol = n.sims)
ensemble_logS_out_fit_18_40 <- matrix(NA, nrow = nrow(full_data[full_data$calendar > 41,]), ncol = n.sims)


##################################################################
########### Perform the simulations ##############################
##################################################################
suppressWarnings({
for (sim in 1:n.sims) {
    set.seed(20200130+sim)
    full_data <- read.csv(sprintf('simulation/triangle_%s-data/sim%s-full-data.csv', tri.size, sim))
    full_data$tau_Ga<-tau_Ga
    full_data$tau_LN<-tau_LN
    outsample_data <- full_data[full_data$calendar > 41,]
    ensemble_logS_out_fit_1_40[, sim] <- adlp_logS(fit_1_40[[sim]], outsample_data, "full")[, -c(1,2)]
    
    ensemble_logS_out_fit_2_40[, sim] <- adlp_logS(fit_2_40[[sim]], outsample_data, "full")[, -c(1,2)]
    
    
    ensemble_logS_out_fit_3_40[, sim] <- adlp_logS(fit_3_40[[sim]], outsample_data, "full")[, -c(1,2)]
    
    
    ensemble_logS_out_fit_4_40[, sim] <- adlp_logS(fit_4_40[[sim]], outsample_data, "full")[, -c(1,2)]
   
    ensemble_logS_out_fit_5_40[, sim] <- adlp_logS(fit_5_40[[sim]], outsample_data, "full")[, -c(1,2)]
    
    
    ensemble_logS_out_fit_6_40[, sim] <- adlp_logS(fit_6_40[[sim]], outsample_data, "full")[, -c(1,2)]
    
    ensemble_logS_out_fit_7_40[, sim] <- adlp_logS(fit_7_40[[sim]], outsample_data, "full")[, -c(1,2)]
   
    ensemble_logS_out_fit_8_40[, sim] <- adlp_logS(fit_8_40[[sim]], outsample_data, "full")[, -c(1,2)]
     
    ensemble_logS_out_fit_9_40[, sim] <- adlp_logS(fit_9_40[[sim]], outsample_data, "full")[, -c(1,2)]
    
    ensemble_logS_out_fit_10_40[, sim] <- adlp_logS(fit_10_40[[sim]], outsample_data, "full")[, -c(1,2)]
    
    
    ensemble_logS_out_fit_11_40[, sim] <- adlp_logS(fit_11_40[[sim]], outsample_data, "full")[, -c(1,2)]
    
    ensemble_logS_out_fit_12_40[, sim] <- adlp_logS(fit_12_40[[sim]], outsample_data, "full")[, -c(1,2)]
    
    ensemble_logS_out_fit_13_40[, sim] <- adlp_logS(fit_13_40[[sim]], outsample_data, "full")[, -c(1,2)]
    
    ensemble_logS_out_fit_14_40[, sim] <- adlp_logS(fit_14_40[[sim]], outsample_data, "full")[, -c(1,2)]
    
    ensemble_logS_out_fit_15_40[, sim] <- adlp_logS(fit_15_40[[sim]], outsample_data, "full")[, -c(1,2)]
    
    ensemble_logS_out_fit_16_40[, sim] <- adlp_logS(fit_16_40[[sim]], outsample_data, "full")[, -c(1,2)]
    
    ensemble_logS_out_fit_17_40[, sim] <- adlp_logS(fit_17_40[[sim]], outsample_data, "full")[, -c(1,2)]
    
    ensemble_logS_out_fit_18_40[, sim] <- adlp_logS(fit_18_40[[sim]], outsample_data, "full")[, -c(1,2)]
    
}

  })

```



```{r}
### Calculate the Log score for SLP:
ensemble_logS_out_fit_0_40 <- matrix(NA, nrow = nrow(full_data[full_data$calendar > 41,]), ncol = n.sims)
suppressWarnings({
for (sim in 1:n.sims) {
    full_data <- read.csv(sprintf('simulation/triangle_%s-data/sim%s-full-data.csv', tri.size, sim))
    full_data$tau_Ga <- tau_Ga
    full_data$tau_LN<- tau_LN
    outsample_data <- full_data[full_data$calendar > 41,]
    
    ensemble_logS_out_fit_0_40[, sim] <- adlp_logS(fit_0_40[[sim]], outsample_data, "full")[, -c(1,2)]
}
  })
```


```{r}
### Calculate the Log score for Equally weighted ensemble:
ensemble_logS_out_fit_EW <- matrix(NA, nrow = nrow(full_data[full_data$calendar > 41,]), ncol = n.sims)

suppressWarnings({
for (sim in 1:n.sims) {
    full_data <- read.csv(sprintf('simulation/triangle_%s-data/sim%s-full-data.csv', tri.size, sim))
    full_data$tau_Ga<-tau_Ga
    full_data$tau_LN<-tau_LN
    outsample_data <- full_data[full_data$calendar > 41,]
    
    ensemble_logS_out_fit_EW[, sim] <- adlp_logS(fit_EW[[sim]], outsample_data, "full")[, -c(1,2)]
}
  })

```

```{r}
### Calculate the Log score for BMV: 

ensemble_logS_out_fit_BMV <- matrix(NA, nrow = nrow(full_data[full_data$calendar > 41,]), ncol = n.sims)

suppressWarnings({
for (sim in 1:n.sims) {
    full_data <- read.csv(sprintf('simulation/triangle_%s-data/sim%s-full-data.csv', tri.size, sim))
    full_data$tau_Ga<-tau_Ga
    full_data$tau_LN<-tau_LN
    outsample_data <- full_data[full_data$calendar > 41,]
    
    ensemble_logS_out_fit_BMV[, sim] <- adlp_logS(fit_BMV[[sim]], outsample_data, "full")[, -c(1,2)]
}

  })
```

Calculate the Log Score by accident periods:

```{r Calculate the Log Score by accident periods}
### Construct a function to calculate scores by accident period:

average_by_ap <- function(origin, data){
    temp_dat <- as.data.frame(cbind(origin, data))
    colnames(temp_dat)[1]  = "origin"
    temp_dat <- temp_dat[order(temp_dat$origin), ]
    LS_ap <- c()
    for (i in 1:length(unique(temp_dat$origin))){
        LS_ap[i] <- mean(apply(temp_dat[temp_dat$origin == unique(temp_dat$origin)[i], -1], FUN = mean, MARGIN = 1))
    }
    return(LS_ap)
}

###  Calculate the Log Score by accident periods: 
LS_ZAGA_ap <- average_by_ap(outsample_data$origin, LS_ZAGA_mat)
LS_PPCF_ap <- average_by_ap(outsample_data$origin, LS_PPCF_mat)
LS_SLP_ap <- average_by_ap(outsample_data$origin, ensemble_logS_out_fit_0_40)
LS_EW_ap <- average_by_ap(outsample_data$origin, ensemble_logS_out_fit_EW)
LS_BMV_ap <- average_by_ap(outsample_data$origin, ensemble_logS_out_fit_BMV)
LS_ADLP1_ap <- average_by_ap(outsample_data$origin, ensemble_logS_out_fit_1_40)
LS_ADLP12_ap <- average_by_ap(outsample_data$origin, ensemble_logS_out_fit_12_40)
LS_ADLP18_ap <- average_by_ap(outsample_data$origin, ensemble_logS_out_fit_18_40)

```


Plot the average Log-score by partition ensemble:

```{r Derive mean log score}
 Mean_LS <- c(mean(ensemble_logS_out_fit_0_40),
              mean(ensemble_logS_out_fit_1_40),
                     mean(ensemble_logS_out_fit_2_40),
                     mean(ensemble_logS_out_fit_3_40),
                     mean(ensemble_logS_out_fit_4_40),
                     mean(ensemble_logS_out_fit_5_40),
                     mean(ensemble_logS_out_fit_6_40),
                     mean(ensemble_logS_out_fit_7_40),
                     mean(ensemble_logS_out_fit_8_40),
                     mean(ensemble_logS_out_fit_9_40),
                     mean(ensemble_logS_out_fit_10_40),
                     mean(ensemble_logS_out_fit_11_40),
                     mean(ensemble_logS_out_fit_12_40),
                     mean(ensemble_logS_out_fit_13_40),
                     mean(ensemble_logS_out_fit_14_40),
                     mean(ensemble_logS_out_fit_15_40),
                     mean(ensemble_logS_out_fit_16_40),
                     mean(ensemble_logS_out_fit_17_40),
                     mean(ensemble_logS_out_fit_18_40))
```


Generate boxplots of log score for each ensemble strategy:

```{r Plot the Log Score boxplots}
# Log Score Boxplots:
ensemble_logS <- list(ADLP_par0 = ensemble_logS_out_fit_0_40, EW = ensemble_logS_out_fit_EW, ADLP_12 = ensemble_logS_out_fit_12_40, BMV = ensemble_logS_out_fit_BMV)
mean_score_over_sim <- lapply(ensemble_logS, FUN = function(x) apply(x, MARGIN = 2, FUN = mean))

#pdf(paste0("plotting/triangle_", tri.size, "_", n.sims, "_LogScoreBoxPlot.pdf"))
ggplot(data=stack(data.frame(mean_score_over_sim)[, c('ADLP_par0', 'BMV', 'EW')]), aes(x = ind, y = values)) + 
    geom_boxplot()+labs(x="Model",y="Log Score") +
    ggtitle("Average Log Score") +
    scale_x_discrete(labels=c('SLP', 'BMV', 'EW'))
#dev.off()

# Log Score by split points: 
plot(x = c(0,split_points_40), y = Mean_LS, main = "Mean Log-score", xlab = "Split points", ylab = "Mean Log Score")
points(x = 0 , y = mean(ensemble_logS_out_fit_0_40), col = "grey", pch = 19)
points(x = 18, y = mean(ensemble_logS_out_fit_12_40), col = "black", pch = 19)
legend("topleft", legend = c("SLP", "Optimal ADLP"), col = c("grey", "black"), pch = c(19,19))

# Log Score by accident periods (1): 
all_ap <- 2:40
plot(x=all_ap, y=LS_PPCF_ap,col="orange",lwd=1,
     ylim=c(-8,0),type="l",main="Log-Score by Accident Periods ",ylab="Mean Log Score",xlab="Accident Periods")
points(x=all_ap, y=LS_ZAGA_ap,col="brown",type="l",lwd=1)
points(x=all_ap,y=LS_BMV_ap,col="green",type="l",lwd=1)
points(x=all_ap,y=LS_SLP_ap,col="yellow",type="l",lwd=1)
points(x=all_ap,y=LS_EW_ap,col="red",type="l",lwd=1)

legend('topright',
       legend=c("PPCF",
                "ZAGA",
                "Best Models in Validation Set",
                "SLP", "Equally Weighted Ensemble"),
       col=c("orange","brown","green","yellow","red"),lty=1,cex=0.6)


# Log Score by accident periods (2):

plot(x=all_ap,y=LS_SLP_ap,col="yellow",type="l",lwd=2, ylim=c(-8,0), main="Log-Score by Accident Periods ",ylab="Mean Log Score",xlab="Accident Periods")
points(x=all_ap,y=LS_ADLP1_ap,col="#2417DA",type="l",lwd=1)
points(x=all_ap,y=LS_ADLP12_ap,col="#6D4691",type="l",lwd=1)
points(x=all_ap,y=LS_ADLP18_ap,col="#FFA500",type="l",lwd=1)
points(x=all_ap,y=LS_EW_ap,col="red",type="l",lwd=1)
points(x=all_ap,y=LS_BMV_ap,col="green",type="l",lwd=1)
legend('topright',
       legend=c("Best Models in Validation Set",
                "SLP","ADLP 1(AP 2-3)","ADLP 12(AP2-18)", "ADLP 18(AP2-33)","Equally Weighted Ensemble"),
       col=c("green","yellow","#2417DA","#6D4691","#FFA500","red"),lty=1,cex=0.6)

```



# Reserve calculation 

## Prediction of central reserve: 

Derive the true reserve: 

```{r Calculate the true reserve}
## Derive the true reserve:

true_reserve <- c() 
    
for (sim in 1:n.sims) {
    full_data <- read.csv(sprintf('simulation/triangle_%s-data/sim%s-full-data.csv', tri.size, sim))
    full_data$tau_Ga<-tau_Ga
    full_data$tau_LN<-tau_LN
    outsample_data <- full_data[full_data$calendar > 41, ]
    ## Calculate the true reserve: 
    true_reserve[sim] <- sum(outsample_data$aggregate_claims)

}

```


```{r Derive the reserve for each combination strategy}

reserve_0_40 <- c()
reserve_12_40 <- c()
reserve_EW <- c()
reserve_BMV <- c()

suppressWarnings({    
for (sim in 1:n.sims) {
    full_data <- read.csv(sprintf('simulation/triangle_%s-data/sim%s-full-data.csv', tri.size, sim))
    full_data$tau_Ga<-tau_Ga
    full_data$tau_LN<-tau_LN
    outsample_data <- full_data[full_data$calendar > 41, ]
    
    ## Calculate the predicted mean for the selected ADLP ensemble and SLP in the paper: 
    res_12_40 <- predict.adlp(fit_12_40[[sim]], outsample_data)
    res_0_40 <- predict.adlp(fit_0_40[[sim]], outsample_data)
    res_EW <- predict.adlp(fit_EW[[sim]], outsample_data)
    res_BMV <- predict.adlp(fit_BMV[[sim]], outsample_data)
    
    ## Calculate the aggregate reserve: 
    reserve_12_40[sim] <- sum(res_12_40$ensemble_mu)
    reserve_0_40[sim] <- sum(res_0_40$ensemble_mu)
    reserve_EW[sim] <- sum(res_EW$ensemble_mu)
    reserve_BMV[sim] <- sum(res_BMV$ensemble_mu)

}
  })
    
```

Calculate the central relative reserve bias: 

```{r Plot the distribution of central relative reserve bias}
## Plot the distribution of the central relative reserve bias: 
central_reserve_estimate <- cbind(reserve_12_40,reserve_BMV, reserve_EW)
relative_diff_centralBias <- (central_reserve_estimate-true_reserve)/true_reserve
colnames(relative_diff_centralBias) = c("ADLP 12","BMV", "EW")

ggplot(data=stack(as.data.frame(relative_diff_centralBias)),aes(x=ind,y=values))+geom_boxplot()+labs(x="Models",y="Relative reserve bias")+ggtitle("Distribution of central relative reserve bias")+ylim(c(-0.5, 0.5))
```



## Simulation of risk margins: 

Simulate the $75^{th}$ reserve quantile:

```{r Simulation of risk margins}
library(tidyverse)
sim_reserve_0_40_mat <- matrix(NA, nrow = 1000, ncol = n.sims)
sim_reserve_EW_mat <- matrix(NA, nrow = 1000, ncol = n.sims)
sim_reserve_12_40_mat <- matrix(NA, nrow = 1000, ncol = n.sims)
sim_reserve_BMV_mat <- matrix(NA, nrow = 1000, ncol = n.sims)

suppressWarnings({
for (sim in 1:n.sims) {
    full_data <- read.csv(sprintf('simulation/triangle_%s-data/sim%s-full-data.csv', tri.size, sim))
    full_data$tau_Ga<-tau_Ga
    full_data$tau_LN<-tau_LN
    outsample_data <- full_data[full_data$calendar > 41, ]
    
    
    ## Simulate the reserves: 
    sim_reserve_0_40 <- adlp_simulate(1000, fit_0_40[[sim]], outsample_data) %>% 
        group_by(sim) %>% 
        summarise(total = sum(simulation))
    
    sim_reserve_EW <- adlp_simulate(1000, fit_EW[[sim]], outsample_data) %>% 
        group_by(sim) %>% 
        summarise(total = sum(simulation))
    
    sim_reserve_12_40 <- adlp_simulate(1000, fit_12_40[[sim]], outsample_data) %>% 
        group_by(sim) %>% 
        summarise(total = sum(simulation))
    
    sim_reserve_BMV <- adlp_simulate(1000, fit_BMV[[sim]], outsample_data) %>% 
        group_by(sim) %>% 
        summarise(total = sum(simulation))
    
    ## Store to the matrices:
    
    sim_reserve_0_40_mat[, sim] <- sim_reserve_0_40$total
    sim_reserve_12_40_mat[, sim] <- sim_reserve_12_40$total
    sim_reserve_EW_mat[, sim] <- sim_reserve_EW$total
    sim_reserve_BMV_mat[, sim] <- sim_reserve_BMV$total
    
    
    #print(paste("This is iteration:", "", sim))
    
}
  })

```


Calculate and plot the reserve quantile bias:

```{r Calculate and plot the reserve quantile bias}
## Calculate the 75 quantile reserve bias: 

quantile_res_75_quantile_SLP <-apply(sim_reserve_0_40_mat, MARGIN = 2, FUN = function(x) quantile(x, 0.75))
quantile_res_75_quantile_ADLP12 <-apply(sim_reserve_12_40_mat, MARGIN = 2, FUN = function(x) quantile(x, 0.75))
quantile_res_75_quantile_EW <-apply(sim_reserve_EW_mat, MARGIN = 2, FUN = function(x) quantile(x, 0.75))
quantile_res_75_quantile_BMV <-apply(sim_reserve_BMV_mat, MARGIN = 2, FUN = function(x) quantile(x, 0.75))


quantile_res_75_quantile <- cbind(quantile_res_75_quantile_ADLP12, quantile_res_75_quantile_EW, quantile_res_75_quantile_BMV)
quantile_res_75_quantile_bias <- (quantile_res_75_quantile-quantile(true_reserve, 0.75))/quantile(true_reserve, 0.75)

colnames(quantile_res_75_quantile_bias) = c("ADLP 12", "EW", "BMV")

ggplot(data=stack(as.data.frame(quantile_res_75_quantile_bias)),aes(x=ind,y=values))+geom_boxplot()+labs(x="Models",y="Relative reserve bias")+ggtitle("Distribution of relative reserve bias(75th quantile)")+ylim(-0.5, 0.5)

```









